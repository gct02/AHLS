import pickle
import subprocess
import argparse
import shutil
from pathlib import Path
from utils.parsers import *
from llvm.opt_utils import *
from estimators.han.cdfg import build_cdfg, print_cdfg

def parse_args():
    parser = argparse.ArgumentParser(
        description="Create CDFGs for the IRs of the Vitis HLS projects in the given folder"
    )
    parser.add_argument("-d", "--dataset", help="Path to the original dataset folder", required=True)
    parser.add_argument("-o", "--output", help="Path where the processed dataset should be written", required=True)
    parser.add_argument("-f", "--filtered", help="Signal that the dataset is filtered", action="store_true")
    return parser.parse_args()

def run_opt(ir_src_path:Path, ir_dst_path:Path, opt_args:str, output_ll:bool=True):
    try:
        if output_ll:
            opt_args += " -S"
        subprocess.check_output(
            f"{OPT} -load {DSE_LIB} {opt_args} < {ir_src_path.as_posix()} > {ir_dst_path.as_posix()};", 
            shell=True
        )
    except subprocess.CalledProcessError as e:
        print(f"Error processing {ir_src_path}: {e}")
        ir_dst_path.unlink(missing_ok=True)
        raise e

def process_ir(
    ir_src_path: Path, 
    ir_dst_path: Path,
    output_md_path: Path,
    directives_path: Path
) -> None:
    """
    Process an LLVM IR generated by Vitis HLS to make it more compact and easier 
    to analyze in order to build a CDFG from it and use it as input to the GNN.

    The following passes are applied (in order) to the IR:

    strip-debug: 
        remove Vitis HLS debug information;
    strip-dead-prototypes: 
        remove unused function prototypes (e.g. llvm.sideeffect);
    instnamer: 
        assign names to anonymous values;
    indirectbr-expand: 
        turn indirectbr into switch instructions;
    lowerinvoke: 
        lower invoke instructions to call instructions;
    lowerswitch: 
        lower switch instructions to branch instructions;
    mem2reg: 
        promote memory to register;
    prep-gnn: 
        prepare the IR for the GNN, removing 'llvm.dbg', 'llvm.lifetime' and 
        '_ssdm_Spec.* intrinsics and implementing 'part.select' and 'part.set';
    update-md: 
        update the metadata of the operations in the IR to include the module's 
        operations IDs, opcodes, bitwidths, and loop information;
    set-hls-md: 
        set metadata to operations and global values in the IR according to the 
        directives used in the solution;
    rename-vals: 
        rename the values in the IR to have standard names based on their 
        position (e.g. %op.1 will occur before %op.2).

    Parameters:
    ----------
    ir_src_path: Path
        Path to the original IR file
    ir_dst_path: Path
        Path to the processed IR file
    directives_path: Path
        Path to the directives file used in the solution

    Raises:
    -------
    subprocess.CalledProcessError
        If any of the LLVM passes fail
    """
    temp1_path = ir_src_path.parent / "temp1.ll"
    temp2_path = ir_src_path.parent / "temp2.ll"
    try:
        run_opt(ir_src_path, temp1_path, "-strip-debug")
        run_opt(temp1_path, temp2_path, "-strip-dead-prototypes")
        run_opt(temp2_path, temp1_path, "-instnamer")
        run_opt(temp1_path, temp2_path, "-indirectbr-expand")
        run_opt(temp2_path, temp1_path, "-lowerinvoke")
        run_opt(temp1_path, temp2_path, "-lowerswitch")
        run_opt(temp2_path, temp1_path, "-mem2reg")
        run_opt(temp1_path, temp2_path, "-prep-gnn")
        run_opt(temp2_path, temp1_path, "-update-md")
        run_opt(temp1_path, temp2_path, "-set-hls-md -dir {}".format(directives_path.as_posix()))
        run_opt(temp2_path, ir_dst_path, "-rename-vals")
        
        subprocess.check_output(
            f"{OPT} -load {DSE_LIB} -extract-md -md {output_md_path.as_posix()} < {ir_dst_path.as_posix()};", 
            shell=True,
            stderr=subprocess.STDOUT
        )
    except subprocess.CalledProcessError as e:
        print(f"Error processing {ir_src_path}: {e}")
        temp1_path.unlink(missing_ok=True)
        temp2_path.unlink(missing_ok=True)
        ir_dst_path.unlink(missing_ok=True)
        raise e
    finally:
        temp1_path.unlink(missing_ok=True)
        temp2_path.unlink(missing_ok=True)


def create_directives_tcl(directives_json: Path, output_path: Path):
    with open(directives_json, "r") as f:
        data = json.load(f)
    directives_tcl = data["HlsSolution"]["DirectiveTcl"]
    with open(output_path, "w") as f:
        directives_tcl = "\n".join(directives_tcl)
        f.write(directives_tcl)

if __name__ == "__main__":
    args = parse_args()
    dataset = Path(args.dataset)
    output_folder_path = Path(args.output)
    filtered = args.filtered

    benchmarks = sorted(list(dataset.iterdir()))

    for i, benchmark in enumerate(benchmarks):
        benchmark_name = benchmark.stem
        output_bench_folder = output_folder_path / benchmark_name
        output_bench_folder.mkdir(parents=True, exist_ok=True)
        solutions = sorted(list(benchmark.iterdir()))
        for j, solution in enumerate(solutions):
            if not solution.is_dir():
                continue

            directives_json_path = solution / f"{solution.stem}_data.json"
            if not directives_json_path.exists():
                print(f"Directives JSON file not found for {solution}")
                continue

            directives_tcl_path = solution / f"directives.tcl"
            create_directives_tcl(directives_json_path, directives_tcl_path)

            if not filtered:
                ir_folder = solution / ".autopilot/db"
                if not ir_folder.exists():
                    print(f"IR folder not found for {solution}")
                    continue

                impl_folder = solution / "impl"
                if not impl_folder.exists():
                    print(f"Implementation folder not found for {solution}")
                    continue
            else:
                ir_folder = solution / "IRs"
                if not ir_folder.exists():
                    print(f"IR folder not found for {solution}")
                    continue

            ir = ir_folder / "a.g.ld.0.bc"
            if not ir.exists():
                print(f"Intermediate representation not found for {solution}")
                continue

            ir_mod = ir_folder / "a.g.ld.0.han.ll"

            output_instance_folder = output_bench_folder / solution.stem
            if output_instance_folder.exists():
                continue

            output_instance_folder.mkdir(parents=True, exist_ok=True)

            output_md_path = output_instance_folder / "metadata.txt"

            try:
                process_ir(ir, ir_mod, output_md_path, directives_tcl_path)
            except subprocess.CalledProcessError:
                output_instance_folder.rmdir()
                continue

            # Copy the modified IR to the output folder
            shutil.copy(ir_mod, output_instance_folder / "ir.ll")

            lut, bram, ff, dsp, clb, latch = extract_utilization(dataset, benchmark_name, solution.stem, filtered)
            wns, tns, target_clk, achieved_clk = extract_timing_summary(dataset, benchmark_name, solution.stem, filtered)
            cc = extract_hls_cc_report(dataset, benchmark_name, solution.stem, filtered)
            
            with open(output_instance_folder / "targets.txt", "w") as f:
                f.write(f"lut={lut}\nff={ff}\ndsp={dsp}\nbram={bram}\nclb={clb}\nlatch={latch}\ncp={achieved_clk}\ncc={cc}")

            cdfg = build_cdfg(ir_mod)

            nodes, edges = cdfg
            print_cdfg(nodes, edges, output_instance_folder / "cdfg.txt", ir_mod)

            with open(output_instance_folder / "cdfg.pkl", "wb") as f:
                pickle.dump(cdfg, f)
