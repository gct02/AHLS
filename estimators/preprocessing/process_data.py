import subprocess
import argparse
import shutil
import json
from os import environ
from pathlib import Path
from typing import Dict


try:
    DSE_LIB = environ['DSE_LIB']
    OPT = environ['OPT']
    CLANG = environ['CLANG']
    LLVM_LINK = environ['LLVM_LINK']
except KeyError as error:
    print(f"Error: environment variable {error.args[0]} not defined.")
    raise


def run_opt(
    ir_src_path: Path, 
    ir_dst_path: Path, 
    opt_args: str, 
    output_ll: bool = True
):
    try:
        if output_ll:
            opt_args += " -S"
        subprocess.check_output(
            f"{OPT} -load {DSE_LIB} {opt_args} < {ir_src_path.as_posix()} > {ir_dst_path.as_posix()};", 
            shell=True, stderr=subprocess.STDOUT
        )
    except subprocess.CalledProcessError as e:
        print(f"Error processing {ir_src_path}: {e}")
        ir_dst_path.unlink(missing_ok=True)
        raise e


def process_ir(ir_src, ir_dst, out_md):
    """
    Process an LLVM IR generated by Vitis HLS to make it more compact and easier 
    to analyze in order to build a CDFG from it and use it as input to the GNN.

    The following passes are applied (in order) to the IR:

    strip-debug: remove Vitis HLS debug information;
    strip-dead-prototypes: remove unused function prototypes (e.g. llvm.sideeffect);
    instnamer: assign names to anonymous values;
    indirectbr-expand: turn indirectbr into switch instructions;
    lowerinvoke: lower invoke instructions to call instructions;
    lowerswitch: lower switch instructions to branch instructions;
    mem2reg: promote memory to register;
    indvars: canonicalize induction variables;
    loop-simplify: simplify the loop structure;
    scalar-evolution: analyze the scalar evolution of the program;
    assign-ids: assign unique IDs to all instructions.
    extract-md: extract metadata from the IR and write it to a file.

    Parameters:
    ----------
    ir_src: Path
        Path to the original IR file
    ir_dst: Path
        Path to the processed IR file
    out_md: Path
        Path to the file where the IR metadata should be written

    Raises:
    -------
    subprocess.CalledProcessError
        If any of the LLVM passes fail
    """
    tmp1 = ir_src.parent / "tmp1.ll"
    tmp2 = ir_src.parent / "tmp2.ll"
    clean_opt = "-instnamer -lowerswitch -lowerinvoke -indirectbr-expand -strip-dead-prototypes -strip-debug"
    transform_opt = "-mem2reg -indvars -loop-simplify -scalar-evolution"

    try:
        run_opt(ir_src, tmp1, clean_opt)
        run_opt(tmp1, tmp2, transform_opt)
        run_opt(tmp2, ir_dst, "-assign-ids")
        subprocess.check_output(
            f"{OPT} -load {DSE_LIB} -extract-md -out {out_md.as_posix()} < {tmp1.as_posix()};", 
            shell=True, stderr=subprocess.STDOUT
        )
    except subprocess.CalledProcessError as e:
        print(f"Error processing {ir_src}: {e}")
        tmp1.unlink(missing_ok=True)
        tmp2.unlink(missing_ok=True)
        ir_dst.unlink(missing_ok=True)
        raise e
    finally:
        tmp1.unlink(missing_ok=True)
        tmp2.unlink(missing_ok=True)


def create_directives_tcl(directives_json: Path, output_path: Path):
    with open(directives_json, "r") as f:
        data = json.load(f)
    directives_tcl = data["HlsSolution"]["DirectiveTcl"]
    with open(output_path, "w") as f:
        directives_tcl = "\n".join(directives_tcl)
        f.write(directives_tcl)


def main(args: Dict[str, str]):
    dataset = Path(args['dataset'])
    output_folder_path = Path(args['output'])
    filtered = args['filtered']
    benchmarks = args['benchmarks']

    if benchmarks is None:
        benchmarks = [b.stem for b in list(dataset.iterdir()) if b.is_dir()]

    for benchmark in benchmarks:
        benchmark_dir = dataset / benchmark
        benchmark_out_dir = output_folder_path / benchmark
        benchmark_out_dir.mkdir(parents=True, exist_ok=True)
        solutions = [s for s in list(benchmark_dir.iterdir()) if s.is_dir()]

        for solution in solutions:
            md_json_path = solution / f"{solution.stem}_data.json"
            if not md_json_path.exists():
                print(f"Directives JSON file not found for {solution}")
                continue
            directives_tcl = solution / f"directives.tcl"
            create_directives_tcl(md_json_path, directives_tcl)

            ir_folder = solution / ("IRs" if filtered else ".autopilot/db")
            ir_path = ir_folder / "a.g.ld.0.bc"
            if not ir_path.exists():
                print(f"Intermediate representation not found for {solution}")
                continue

            solution_out_dir = benchmark_out_dir / solution.stem
            solution_out_dir.mkdir(parents=True, exist_ok=True)
            ir_mod_path = ir_folder / "a.g.ld.0.dse.ll"
            out_md_path = solution_out_dir / "metadata.txt"
            try:
                process_ir(ir_path, ir_mod_path, directives_tcl, out_md_path)
            except subprocess.CalledProcessError:
                print(f"Error processing {ir_path}")
                shutil.rmtree(solution_out_dir)
                continue

            metrics = extract_metrics(solution, filtered=filtered)
            with open(solution_out_dir / "metrics.json", "w") as f:
                json.dump(metrics, f, indent=2)

            build_graph(
                ir_mod_path, out_md_path, 
                directive_file_path=directives_tcl,
                output_path=solution_out_dir
            )


def parse_args():
    parser = argparse.ArgumentParser(
        description="Create pytorch geometric HeteroData objects from Vitis HLS solutions"
    )
    parser.add_argument("-d", "--dataset", required=True,
                        help="Path to the original dataset folder")
    parser.add_argument("-o", "--output", required=True,
                        help="Path where the processed dataset should be written")
    parser.add_argument("-f", "--filtered", action="store_true",
                        help="Signal that the dataset is filtered")
    parser.add_argument("-b", "--benchmarks", nargs="+", default=None,
                        help="List of benchmarks to process")
    return vars(parser.parse_args())


if __name__ == "__main__":
    import sys

    if __package__ is None:                  
        DIR = Path(__file__).resolve().parent
        sys.path.insert(0, str(DIR.parent))
        sys.path.insert(0, str(DIR.parent.parent))
        __package__ = DIR.name

    from estimators.graph import build_graph
    from utils.parsers import extract_metrics

    args = parse_args()
    main(args)

