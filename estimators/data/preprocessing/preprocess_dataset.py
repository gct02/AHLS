from typing import Dict

import subprocess
import argparse
import shutil
import json
from os import environ
from pathlib import Path

try:
    DSE_LIB = environ['DSE_LIB']
    OPT = environ['OPT']
    CLANG = environ['CLANG']
    LLVM_LINK = environ['LLVM_LINK']
except KeyError as error:
    print(f"Error: environment variable {error.args[0]} not defined.")
    raise

def run_opt(
    ir_src_path: Path, 
    ir_dst_path: Path, 
    opt_args: str, 
    output_ll: bool = True
):
    try:
        if output_ll:
            opt_args += " -S"
        subprocess.check_output(
            f"{OPT} -load {DSE_LIB} {opt_args} < {ir_src_path.as_posix()} > {ir_dst_path.as_posix()};", 
            shell=True, stderr=subprocess.STDOUT
        )
    except subprocess.CalledProcessError as e:
        print(f"Error processing {ir_src_path}: {e}")
        ir_dst_path.unlink(missing_ok=True)
        raise e

def process_ir(
    ir_src_path: Path, 
    ir_dst_path: Path,
    output_md_path: Path,
    output_cfg_path: Path,
    directives_path: Path
) -> None:
    """
    Process an LLVM IR generated by Vitis HLS to make it more compact and easier 
    to analyze in order to build a CDFG from it and use it as input to the GNN.

    The following passes are applied (in order) to the IR:

    strip-debug: remove Vitis HLS debug information;
    strip-dead-prototypes: remove unused function prototypes (e.g. llvm.sideeffect);
    instnamer: assign names to anonymous values;
    indirectbr-expand: turn indirectbr into switch instructions;
    lowerinvoke: lower invoke instructions to call instructions;
    lowerswitch: lower switch instructions to branch instructions;
    prep-gnn: prepare the IR for the GNN, removing 'llvm.dbg', 'llvm.lifetime' and 
        '_ssdm_Spec.* intrinsics and implementing 'part.select' and 'part.set';
    update-md: update the metadata of the operations in the IR to include the module's 
        operations IDs, opcodes, bitwidths, and loop information;
    set-hls-md: set metadata to operations and global values in the IR according to the 
        directives used in the solution;
    rename-vals: rename the values in the IR to have standard names based on their 
        position (e.g. %op.1 will occur before %op.2).

    Parameters:
    ----------
    ir_src_path: Path
        Path to the original IR file
    ir_dst_path: Path
        Path to the processed IR file
    output_md_path: Path
        Path to the file where the metadata extracted from the IR will be written
    output_cfg_path: Path
        Path to the file where the CFG extracted from the IR will be written
    directives_path: Path
        Path to the directives file used in the solution

    Raises:
    -------
    subprocess.CalledProcessError
        If any of the LLVM passes fail
    """
    tmp1 = ir_src_path.parent / "tmp1.ll"
    tmp2 = ir_src_path.parent / "tmp2.ll"

    default_opt = "-mem2reg -indvars -loop-simplify -scalar-evolution -indvars -mem2reg -lowerswitch -lowerinvoke -indirectbr-expand -instnamer -strip-dead-prototypes -strip-debug"
    try:
        run_opt(ir_src_path, tmp1, default_opt)
        run_opt(tmp1, tmp2, "-prep-gnn")
        run_opt(tmp2, tmp1, "-update-md")
        run_opt(tmp1, tmp2, f"-set-hls-md -dir {directives_path.as_posix()}")
        run_opt(tmp2, tmp1, "-rename-vals")
        
        subprocess.check_output(
            f"{OPT} -load {DSE_LIB} -extract-md -out-md {output_md_path.as_posix()} < {tmp1.as_posix()};", 
            shell=True, stderr=subprocess.STDOUT
        )
        
        run_opt(tmp1, ir_dst_path, "-rm-dummy-globals")

        subprocess.check_output(
            f"{OPT} -load {DSE_LIB} -write-cfg -out-cfg {output_cfg_path.as_posix()} < {ir_dst_path.as_posix()};", 
            shell=True, stderr=subprocess.STDOUT
        )
    except subprocess.CalledProcessError as e:
        print(f"Error processing {ir_src_path}: {e}")
        tmp1.unlink(missing_ok=True)
        tmp2.unlink(missing_ok=True)
        ir_dst_path.unlink(missing_ok=True)
        raise e
    finally:
        tmp1.unlink(missing_ok=True)
        tmp2.unlink(missing_ok=True)


def create_directives_tcl(directives_json: Path, output_path: Path):
    with open(directives_json, "r") as f:
        data = json.load(f)
    directives_tcl = data["HlsSolution"]["DirectiveTcl"]
    with open(output_path, "w") as f:
        directives_tcl = "\n".join(directives_tcl)
        f.write(directives_tcl)

def main(args: Dict[str, str]):
    dataset = Path(args['dataset'])
    output_folder_path = Path(args['output'])
    filtered = args['filtered']
    benchmarks = args['benchmarks']

    if benchmarks is None:
        # Process all benchmarks in the dataset
        benchmarks = [b.stem for b in list(dataset.iterdir())]

    for benchmark in benchmarks:
        benchmark_dir = dataset / benchmark
        output_bench_folder = output_folder_path / benchmark
        output_bench_folder.mkdir(parents=True, exist_ok=True)
        solutions = list(benchmark_dir.iterdir())

        for solution in solutions:
            if not solution.is_dir():
                continue

            directives_json_path = solution / f"{solution.stem}_data.json"
            if not directives_json_path.exists():
                print(f"Directives JSON file not found for {solution}")
                continue

            directives_tcl_path = solution / f"directives.tcl"
            create_directives_tcl(directives_json_path, directives_tcl_path)

            if not filtered:
                ir_folder = solution / ".autopilot/db"
                if not ir_folder.exists():
                    print(f"IR folder not found for {solution}")
                    continue

                impl_folder = solution / "impl"
                if not impl_folder.exists():
                    print(f"Implementation folder not found for {solution}")
                    continue
            else:
                ir_folder = solution / "IRs"
                if not ir_folder.exists():
                    print(f"IR folder not found for {solution}")
                    continue

            ir = ir_folder / "a.g.ld.0.bc"
            if not ir.exists():
                print(f"Intermediate representation not found for {solution}")
                continue

            output_instance_folder = output_bench_folder / solution.stem
            output_instance_folder.mkdir(parents=True, exist_ok=True)

            ir_mod = ir_folder / "a.g.ld.0.dse.ll"
            output_md_path = output_instance_folder / "metadata.txt"
            output_cfg_path = output_instance_folder / "cfg_edges.txt"

            try:
                process_ir(ir, ir_mod, output_md_path, output_cfg_path, directives_tcl_path)
            except subprocess.CalledProcessError:
                output_instance_folder.rmdir()
                continue

            # Copy the modified IR to the output folder
            shutil.copy(ir_mod, output_instance_folder / "ir.ll")

            lut, bram, ff, dsp, clb, latch = extract_utilization(
                dataset, benchmark, solution.stem, filtered
            )
            _, _, _, achieved_clk = extract_timing_summary(
                dataset, benchmark, solution.stem, filtered
            )
            cc = extract_hls_cc_report(
                dataset, benchmark, solution.stem, filtered
            )
            
            with open(output_instance_folder / "targets.txt", "w") as f:
                f.write(f"lut={lut}\nff={ff}\ndsp={dsp}\nbram={bram}\nclb={clb}\nlatch={latch}\ncp={achieved_clk}\ncc={cc}")

            build_cdfg(
                ir_mod, output_md_path, output_cfg_path, 
                output_instance_folder
            )

def parse_args():
    parser = argparse.ArgumentParser(
        description="Create CDFGs for the IRs of the Vitis HLS projects in the given folder"
    )
    parser.add_argument("-d", "--dataset", help="Path to the original dataset folder", required=True)
    parser.add_argument("-o", "--output", help="Path where the processed dataset should be written", required=True)
    parser.add_argument("-f", "--filtered", help="Signal that the dataset is filtered", action="store_true")
    parser.add_argument("-b", "--benchmarks", help="List of benchmarks to process", nargs="+", default=None)
    return vars(parser.parse_args())

if __name__ == "__main__":
    import sys

    if __package__ is None:                  
        DIR = Path(__file__).resolve().parent
        sys.path.insert(0, str(DIR.parent))
        sys.path.insert(0, str(DIR.parent.parent))
        __package__ = DIR.name

    from cdfg import build_cdfg, print_cdfg
    from utils.parsers import extract_utilization, extract_timing_summary, extract_hls_cc_report

    args = parse_args()
    main(args)

